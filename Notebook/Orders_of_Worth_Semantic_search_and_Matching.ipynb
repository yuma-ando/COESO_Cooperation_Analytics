{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d6yBE7DEq94_",
    "outputId": "56311f98-755b-467e-a5bc-35a214fec1f0"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim\n",
    "from re import sub\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity\n",
    "# Load the model: this is a big file, can take a while to download and open\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
    "\n",
    "!pip install contractions\n",
    "!pip install googletrans==4.0.0-rc1\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import contractions\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq6iskUoouIU"
   },
   "outputs": [],
   "source": [
    "# reading .csv dataset, cleaned manually in order to remove greetings and PROPER NOUN at the beginning and at the end of the email\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"put_csv_file_here.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "457Hj5mxrkJ9"
   },
   "outputs": [],
   "source": [
    "#Translate text to English\n",
    "data['Translated'] = data['Body'].apply(lambda x: translator.translate(x, dest='en').text)\n",
    "\n",
    "#Extend Contractions\n",
    "data[\"Extended\"] = data['Translated'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fd2lZj0_q10q",
    "outputId": "e75225ba-1a07-48c8-9dec-5077e9c51213"
   },
   "outputs": [],
   "source": [
    "#Sort by month if needed\n",
    "month_sort = data.loc[data.Date.str.contains('May', na=False)]    #Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug\n",
    "text = month_sort[\"Extended\"].to_list()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfsij16IRH3y",
    "outputId": "ecf60430-80b1-4d5a-f8d9-23ba5df25de0"
   },
   "outputs": [],
   "source": [
    "#without sorting by months\n",
    "text = data[\"Extended\"].to_list()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzpushEgcu3I",
    "outputId": "c8c7b297-f8b0-4627-b43d-b1e0b60b2342"
   },
   "outputs": [],
   "source": [
    "#preprocessing and cleaning\n",
    "import re\n",
    "import string\n",
    "from six.moves.html_parser import HTMLParser\n",
    "h = HTMLParser()\n",
    "target = string.printable + \"öäüÖÄÜ\"\n",
    "\n",
    "def clean(value):\n",
    "  sentences = []\n",
    "  for v in text:\n",
    "    if type(v) is not str:\n",
    "        continue\n",
    "    doc = re.sub (\"\\n\", \" \", v)\n",
    "    doc = re.sub (\"\\r\", \" \",doc)\n",
    "    doc = re.sub(\"http\\S+\", \" \", doc) #removing urls\n",
    "    doc = re.sub(\"[`~!@#$%^&*()_|+\\-=?;:'<>\\{\\}\\[\\]\\\\\\/]\", ' ', doc)\n",
    "    doc = h.unescape(doc) #converting other HTML entities to recongisable characters\n",
    "    doc = re.sub(\"(\\s|\\t){2,}\", \" \", doc) #removing unnecessary spaces\n",
    "    doc = re.sub(\"\\S*@\\S*\\s?\", \" \", doc) #removing emails\n",
    "    doc = re.sub(\"@[^\\d]\", \" \", doc) #removing phone numbers\n",
    "    sentences.append(doc.strip()) #removing leading and trailing spaces and adding clean string to the list\n",
    "  return sentences\n",
    "\n",
    "\n",
    "clean_sents = clean(text)\n",
    "print(\"clean_sents\")\n",
    "print(len(clean_sents))\n",
    "print(clean_sents)\n",
    "\n",
    "def split_sentences (cleaned_sents):\n",
    "    doc = nlp(str(clean_sents))\n",
    "    splitted_sent = []\n",
    "    for sent in doc.sents:\n",
    "        splitted = sent.text\n",
    "        splitted_sent.append(splitted)\n",
    "    print(len(splitted_sent))\n",
    "    return splitted_sent\n",
    "\n",
    "final_text = split_sentences(clean_sents)\n",
    "\n",
    "def remove_duplicates(sents):\n",
    "  unique_sents = []\n",
    "  for sent in sents:\n",
    "    if sent not in unique_sents:\n",
    "      unique_sents.append(sent)\n",
    "  return unique_sents\n",
    "\n",
    "removed_dup = remove_duplicates(final_text)\n",
    "print(len(removed_dup))\n",
    "\n",
    "filtered_sent = [sent for sent in removed_dup if len(sent) > 10 and len(sent) < 100]\n",
    "print(len(filtered_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHk_HeNksKT-"
   },
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d[\"domestic\"] = [\"esteem\", \"reputation\", \"oral format of information\", \"exemplary format of information\" , \"anecdotal information\", \"trust\", \"authority\"]\n",
    "d['industrial'] = [\"productivity\", \"efficiency\", \"criteria\", \"statistics\", \"functional link\", \"professiional competency\", \"expertise\"]\n",
    "d['project'] = [\"projects\", \"network expansion\", \"proliferation of links\", \"to coordinate\", \"to adjust to others\", \"engaged\", \"engaging\", \"enthusiastic\", \"involved\", \"flexible\", \"adaptable\", \"scalable\", \"employable\", \"autonomous\", \"project manager\", \"coach\", \"expert\", \"supplier\", \"innovator\", \"connection tools\", \"new technologies\", \"informal relationships\", \"trust relationships\", \"partnership\", \"outsourcing\", \"business networks\", \"network companies\", \"synapse\", \"authoritarian\", \"rigid\", \"network shutdown\", \"redistribution of connections\", \"insert into networks\", \"provide employability\", \"the end of a project\", \"the start of another project\", \"to be called upon to participate\", \"to involve\", \"to reject\", \"need to be linked\", \"network\"]\n",
    "d['market'] = [\"price\", \"monetory format of information\", \"exchange\", \"desire\", \"purchasing power\"]\n",
    "d['civic'] = [\"collective interest\", \"formal format of information\", \"official format of information\", \"solidarity\", \"equality\"]\n",
    "d['inspiration'] = [\"grace\", \"nonconformity\", \"creativeness\", \"emotional format of information\", \"passion\", \"creativity\", \"ingenuity\"]\n",
    "d['opinion'] = [\"renown\", \"semiotic format of information\", \"recognition\", \"celebrity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative extended list of dic\n",
    "d= dict()\n",
    "d[\"inspiration\"]=['inspiration','unspeakable and ethereal','weird','unusual','marvellous','unspeakable','disturbing','exciting','spontaneous','emotional','concern for creation','love','passion','create','the enlightened','mind','fairy','shadow','freak','I','child','women','mad','artist','the waking dream','body','dream','unconscious','dope','escape from habits','question','risk','detour','the universal value of singularity','independent','genius','the alchemy of unexpected encounters','discover','to research','imagine','dream','explode','TO DO','the reality of the imaginary','imaginary','unconscious','uses','proprieties','adventure','quest','mental journey','lived experience','illumination','intuition','almost appear','vertigo','surpass oneself','masterpiece','hover','will have','fantasy','the certainty of intuition','symbol','signs']\n",
    "d[\"domestic\"]=['generation','hierarchy','tradition','hierarchical superiority','caring','well-mannered','easy','distinct','discreet','reserve','trustworthy','franc','faithful','ease of habit','fold','common sense','natural','character','the superiors and the inferiors','father','king','ascendants','parents','family','person','boss','chief','child','women','foreign','Single','I','Me','dog','cat','others','visitor','surroundings','neighbors','third','the rules of good manners','good manners','propriety','rank','title','remains','presentation','signature','announcement','gifts','flowers','rejection of selfishness','helpfulness','duty (and she)','harmony','respect and responsibility','authority','subordination','respectability','honor','shame','the trade of well-mannered people','reproduce','give birth','educate','invite','give','receive','render','recommend','thank','respect','the soul of the home','family','environment','principle','party','birth','death','marriage','worldliness','conversation','distinction','nomination','enjoy','congratulate','admonitions','report','the exemplary anecdote','give an example','prejudice']\n",
    "d['project'] = [\"projects\", \"network expansion\", \"proliferation of links\", \"to coordinate\", \"to adjust to others\", \"engaged\", \"engaging\", \"enthusiastic\", \"involved\", \"flexible\", \"adaptable\", \"scalable\", \"employable\", \"autonomous\", \"project manager\", \"coach\", \"expert\", \"supplier\", \"innovator\", \"connection tools\", \"new technologies\", \"informal relationships\", \"trust relationships\", \"partnership\", \"outsourcing\", \"business networks\", \"network companies\", \"synapse\", \"authoritarian\", \"rigid\", \"network shutdown\", \"redistribution of connections\", \"insert into networks\", \"provide employability\", \"the end of a project\", \"the start of another project\", \"to be called upon to participate\", \"to involve\", \"to reject\", \"need to be linked\", \"network\"]\t\t\t\t\t\t\t\n",
    "d['industrial']=['efficiency','performance','coming','functional','efficient','reliable','operational','energy','work','professionals','experts','specialists','responsible','operator','tools','resources','method','stain','space','environment','axis','direction','criteria','definition','list','chart','plan','calendar','plan','objective','quantity','variable','series','mean','probability','nun','factor','cause','progress','investment','sympathy','detachment','mastery','function','implement','gear linkages','be a function of','cog','need','to condition','necessary relationship','to integrate','arrange','control','stabilize','to expect','implant','adapted','detect','analyze','take into account','determine','highlight','measure','formalize','standardization','to optimise','solve','to treat','organization','system','test','launch','getting started','Implementation','achievement','effective','correct','in working order','functioning','measure']\n",
    "d['market'] =['competition','rivalry','competition','desirable','salable','value','millionaire','winner','hated','unsuitable','random','interest','desire','selfishness','competitors','business man','seller','customer','Buyer','self employed','richness','luxury items','opportunism','freedom','opening','pay attention to others','dynamic','emotional distance','take a step back','possess','to interest','buy','produce','sell','to be in business with','negotiate','benefit','monetize','pay','compete','market','affair','case settled','in the bag','bargain','price','justified value','reasonable value','true value','money','profit','result','retribution']\n",
    "d['civic']=['the pre-eminence of collectives','collective','all','general will','regulatory and representative','unitary','legal','regulatory','official','representative','allowed','incumbent','free','the aspiration to civil rights','civil rights','political aspirations','participation','public authorities','left','federation','section','desk','committee','elected','representing','delegate','secretary','member','right','legislation','decree','arrangement','measure','courts','formality','procedure','protocol of agreement','exemption','electoral capacity','coded','criteria','riding','electoral list','program','orientation','statement','attach','brochure','newsletter','leaflet','slogan','seat','permanence','local','acronym','map','solidarity','exceed','to renouncer','struggle','delegation reports','membership','representation','delegation','translate aspirations','unify','mobilize','gather','exclude','join','rally','make a call','discuss','speak','inform','codify','legalize','empower','go to court','the democratic republic','Republic','state','democracy','base','electorate','representative institutions','parliament','assembly','Congress','advice','meeting','session','movement','manifest the presence','dispute','appeal','justice','the verdict of the ballot','rumor','noise','fashion','coast','resounding','vote','election','consultation','mobilization','measure audience','law','legal rules','statutes']\n",
    "d['opinion']=['the reality of opinion','others','General public','Fame','famous','recognized','visible','hit','be successful','stand out','persuasive','catchy','the desire to be recognized','self-esteem','consideration','desire to','stars and supporters','a personality','opinion leader','spokesperson','relay','journalist','Press officer','names in the media','brand','message','transmitter','receiver','campaign','public relations','press','interview','communicated','support','brochure','mailing','badge','audio-visual','atmosphere','decor','reconcentration to secrecy','reveal','to be recognized','identify','identification','strength','persuasion','influence','convince','to raise awareness','hang','seduce','drill','capture','throw','issue','circulate','propagate','discuss','speak up','promote','orient','amplify','talk about','to quote','public image','audience','target','positioning','the presentation of the event','expression','press conference','imagination','open door','evidence of success','known','repercussion','reduce to','cause','rally to','awareness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxqqXrDyrNrB",
    "outputId": "0bc009e2-77af-4e6f-eadf-3b5c3609b28d"
   },
   "outputs": [],
   "source": [
    "for (name, v) in d.items():\n",
    "  query_string = str(v)\n",
    "\n",
    "  documents = filtered_sent\n",
    "\n",
    "  stopwords = ['the', 'and', 'are', 'a', \"/\"]\n",
    "\n",
    "  def preprocess(doc):\n",
    "      # Tokenize, clean up input document string\n",
    "      doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "      doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "      doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "      doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "      return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]\n",
    "\n",
    "  # Preprocess the documents, including the query string\n",
    "  corpus = [preprocess(document) for document in documents]\n",
    "  query = preprocess(query_string)\n",
    "\n",
    "  # Build the term dictionary, TF-idf model\n",
    "  dictionary = Dictionary(corpus+[query])\n",
    "  tfidf = TfidfModel(dictionary=dictionary)\n",
    "\n",
    "  # Create the term similarity matrix.\n",
    "  similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)\n",
    "\n",
    "\n",
    "  # Compute Soft Cosine Measure between the query and the documents.\n",
    "  query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "\n",
    "  index = SoftCosineSimilarity(\n",
    "              tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "              similarity_matrix)\n",
    "\n",
    "  doc_similarity_scores = index[query_tf]\n",
    "\n",
    "\n",
    "  # Output the sorted similarity scores and documents\n",
    "  sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "  print(name)\n",
    "  for idx in sorted_indexes:\n",
    "      #similarity_results = f'\\n {doc_similarity_scores[idx]:0.3f} \\t {documents[idx]}'\n",
    "      if doc_similarity_scores[idx] > 0.1:\n",
    "          similarity_results = f'\\n {doc_similarity_scores[idx]:0.3f} \\t {documents[idx]}'\n",
    "\n",
    "          print(similarity_results)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
